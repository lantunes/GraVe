The models in this directory were created with the following settings:

<table>
 <tr>
    <th colspan="4">&nbsp;</th>
    <th colspan="8">GloVe</th>
 </tr>
 <tr>
    <th>Model</th>
    <th>Walk Method</th>
    <th>Walks</th>
    <th>Walk Length</th>
    <th>Window</th>
    <th>Components</th>
    <th>Epochs</th>
    <th>Learning Rate</th>
    <th>Workers</th>
    <th>alpha</th>
    <th>max_count</th>
    <th>max_loss</th>
 </tr>
 <tr>
    <td>karate.*</td>
    <td>DeepWalk</td>
    <td>10</td>
    <td>40</td>
    <td>10</td>
    <td>2</td>
    <td>10</td>
    <td>0.05</td>
    <td>1</td>
    <td>0.75</td>
    <td>100</td>
    <td>10.0</td>
 </tr>
 <tr>
    <td>karate2.*</td>
    <td>DeepWalk</td>
    <td>160</td>
    <td>40</td>
    <td>1</td>
    <td>2</td>
    <td>200</td>
    <td>0.05</td>
    <td>1</td>
    <td>0.75</td>
    <td>100</td>
    <td>10.0</td>
 </tr>
 <tr>
    <td>karate3.*</td>
    <td>node2vec</td>
    <td>160</td>
    <td>40</td>
    <td>10</td>
    <td>2</td>
    <td>200</td>
    <td>0.05</td>
    <td>1</td>
    <td>0.75</td>
    <td>100</td>
    <td>10.0</td>
 </tr>
</table>

Compared to the `karate` model, the `karate2` model was trained on a larger walk dataset, as well as with many more 
epochs and a symmetric context window size of 1. The embeddings in the `karate` model appear to be clustered according 
to node degree, whereas the embeddings in the `karate2` model appear to be clustered according to community structure.
  
The `karate3` model was trained on a walk dataset generated by the node2vec approach. The embeddings in this model are
clustered according to community structure, but the GloVe context window size was 10.